{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch as T\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nimport re\nimport jellyfish","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu\nfrom nltk.translate.meteor_score import meteor_score\nfrom nltk.tokenize import word_tokenize","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import CountVectorizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('omw-1.4')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cleanString(string):\n    return re.compile('\\W+').sub(' ', string).strip()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def meteorScore(s1, s2):\n    s1 = word_tokenize(s1)\n    s2 = word_tokenize(s2)\n    \n    return nltk.translate.meteor_score.single_meteor_score(s1, s2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cosineSimilarity(s1, s2):\n    vectorizer = CountVectorizer()\n    cos_vectors = vectorizer.fit_transform([s1, s2])\n    return cosine_similarity(cos_vectors[0], cos_vectors[1])[0][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ngrams(s1, s2, n):\n    t1 = word_tokenize(s1)\n    t2 = word_tokenize(s2)\n    \n    ngrams1 = nltk.ngrams(t1, n)\n    ngrams2 = nltk.ngrams(t2, n)\n    \n    overlap = set(ngrams1).intersection(set(ngrams2))\n    \n    return len(overlap)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jaccard(s1, s2):\n    s1 = word_tokenize(s1)\n    s2 = word_tokenize(s2)\n    \n    intersection = len(set(s1).intersection(s2))\n    union = len(s1 + s2) - intersection\n    \n    return float(intersection) / union","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sorensonDice(s1, s2):\n    s1 = set(s1)\n    s2 = set(s2)\n    \n    return (2 * len(s1.intersection(s2))) / (len(s1) + len(s2))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def amntOverlap(s1, s2):\n    s1 = s1.split()\n    s2 = s2.split()\n    \n    return len(set(s1).intersection(set(s2)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preprocess dataFrame and add features\ndef preprocess(txtFile):\n    columns = ['id', 's1', 's2', 'gold label']\n    df = pd.read_csv(txtFile, sep = '\\t+', names = columns, engine = 'python')\n    \n    df['s1'] = df.apply(lambda row: cleanString(row['s1']), axis = 1)\n    df['s2'] = df.apply(lambda row: cleanString(row['s2']), axis = 1)\n    \n    df['length difference'] = df.apply(lambda row: abs(len(row['s1'].split(\" \")) - len(row['s2'].split(\" \"))), axis = 1) \n    df['lev distance'] = df.apply(lambda row: nltk.edit_distance(row['s1'], row['s2']), axis = 1)\n    df['meteor score'] = df.apply(lambda row: meteorScore(row['s1'], row['s2']), axis = 1)\n    df['bleu 1'] = df.apply(lambda row: sentence_bleu([row['s1']], row['s2']), axis = 1)\n    df['bleu 2'] = df.apply(lambda row: sentence_bleu([row['s1']], row['s2'], weights = (0.5, 0.5)), axis = 1)\n    df['bleu 3'] = df.apply(lambda row: sentence_bleu([row['s1']], row['s2'], weights = (1/3, 1/3, 1/3)), axis = 1)\n    df['bleu 4'] = df.apply(lambda row: sentence_bleu([row['s1']], row['s2'], weights = (0.25, 0.25, 0.25, 0.25)), axis = 1)\n    df['cosine similarity'] = df.apply(lambda row: cosineSimilarity(row['s1'], row['s2']), axis = 1)\n    df['2 ngrams'] = df.apply(lambda row: ngrams(row['s1'], row['s2'], 2), axis = 1)\n    df['3 ngrams'] = df.apply(lambda row: ngrams(row['s1'], row['s2'], 3), axis = 1)\n    df['jaccard similarity'] = df.apply(lambda row: jaccard(row['s1'], row['s2']), axis = 1)\n    df['sorenson dice score'] = df.apply(lambda row: sorensonDice(row['s1'], row['s2']), axis = 1)\n    df['jaro winkler dist.'] = df.apply(lambda row: jellyfish.jaro_winkler(row['s1'], row['s2']), axis = 1)\n    df['# overlap'] = df.apply(lambda row: amntOverlap(row['s1'], row['s2']), axis = 1)\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preprocess test Dataframe\ndef preprocessTest(testFile):\n    columns = ['instance id', 's1', 's2']\n    df = pd.read_csv(testFile, sep = '\\t+', names = columns, engine = 'python')\n    \n    df['s1'] = df.apply(lambda row: cleanString(row['s1']), axis = 1)\n    df['s2'] = df.apply(lambda row: cleanString(row['s2']), axis = 1)\n    \n    df['length difference'] = df.apply(lambda row: abs(len(row['s1'].split(\" \")) - len(row['s2'].split(\" \"))), axis = 1) \n    df['lev distance'] = df.apply(lambda row: nltk.edit_distance(row['s1'], row['s2']), axis = 1)\n    df['meteor score'] = df.apply(lambda row: meteorScore(row['s1'], row['s2']), axis = 1)\n    df['bleu 1'] = df.apply(lambda row: sentence_bleu([row['s1']], row['s2']), axis = 1)\n    df['bleu 2'] = df.apply(lambda row: sentence_bleu([row['s1']], row['s2'], weights = (0.5, 0.5)), axis = 1)\n    df['bleu 3'] = df.apply(lambda row: sentence_bleu([row['s1']], row['s2'], weights = (1/3, 1/3, 1/3)), axis = 1)\n    df['bleu 4'] = df.apply(lambda row: sentence_bleu([row['s1']], row['s2'], weights = (0.25, 0.25, 0.25, 0.25)), axis = 1)\n    df['cosine similarity'] = df.apply(lambda row: cosineSimilarity(row['s1'], row['s2']), axis = 1)\n    df['2 ngrams'] = df.apply(lambda row: ngrams(row['s1'], row['s2'], 2), axis = 1)\n    df['3 ngrams'] = df.apply(lambda row: ngrams(row['s1'], row['s2'], 3), axis = 1)\n    df['jaccard similarity'] = df.apply(lambda row: jaccard(row['s1'], row['s2']), axis = 1)\n    df['sorenson dice score'] = df.apply(lambda row: sorensonDice(row['s1'], row['s2']), axis = 1)\n    df['jaro winkler dist.'] = df.apply(lambda row: jellyfish.jaro_winkler(row['s1'], row['s2']), axis = 1)\n    df['# overlap'] = df.apply(lambda row: amntOverlap(row['s1'], row['s2']), axis = 1)\n    \n    return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create class for testing datasets\nclass TestDataSet(Dataset):\n    def __init__(self, path):\n        df = preprocessTest(path)\n        self.X = T.tensor(df.iloc[:, 3:].values, dtype = T.float32)\n        \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        return T.tensor(self.X[idx])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create class for preprocessing training/validation datasets\nclass ParaphraseDataSet(Dataset):\n    def __init__(self, path):\n        df = preprocess(path)\n        self.X = T.tensor(df.iloc[:, 4:].values, dtype = T.float32)\n        self.y = T.tensor(df.iloc[:, 3].values, dtype = T.float32)\n        self.y = self.y.reshape(-1, 1)\n    \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        return [self.X[idx], self.y[idx]]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create Multilayer Perceptron\nclass MLPNet(T.nn.Module):\n    def __init__(self, input_size): #input layer perceptrons = # of features\n        super(MLPNet, self).__init__()\n        self.input_size = input_size\n        self.hidden_1 = T.nn.Linear(input_size, input_size*2)\n        self.hidden_2 = T.nn.Linear(input_size*2, input_size*2)\n        self.hidden_3 = T.nn.Linear(input_size*2, input_size*2)\n        self.output = T.nn.Linear(input_size*2, 1)\n        \n        #initialize weights and biases using xavier uniform distribution (random)\n        T.nn.init.xavier_uniform_(self.hidden_1.weight)\n        T.nn.init.zeros_(self.hidden_1.bias)\n        \n        T.nn.init.xavier_uniform_(self.hidden_2.weight)\n        T.nn.init.zeros_(self.hidden_2.bias)\n        \n        T.nn.init.xavier_uniform_(self.hidden_3.weight)\n        T.nn.init.zeros_(self.hidden_3.bias)\n        \n        T.nn.init.xavier_uniform_(self.output.weight)\n        T.nn.init.zeros_(self.output.bias)\n       \n    #FeedForward\n    def forward(self, x):\n        x = T.relu(self.hidden_1(x))\n        x = T.tanh(self.hidden_2(x))\n        x = T.relu(self.hidden_3(x))\n        x = T.sigmoid(self.output(x))\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DataLoaders\ntraining = ParaphraseDataSet('/kaggle/input/mlfinalprojectdataset/train_with_label.txt')\nvalidation = ParaphraseDataSet('/kaggle/input/mlfinalprojectdataset/dev_with_label.txt')\ntesting = TestDataSet('/kaggle/input/mlfinalprojectdataset/test_without_label.txt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = T.utils.data.DataLoader(dataset = training, batch_size = 1000, shuffle = True)\nvalidation_loader = T.utils.data.DataLoader(dataset = validation, batch_size = 1000, shuffle = False)\ntest_loader = T.utils.data.DataLoader(dataset = testing, batch_size = 1000, shuffle = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Instantiate Model and set Hyperparameters\nMLP_model = MLPNet(14)\nlearn_rate = 0.01\nepochs = 1000\ncriterion = T.nn.BCELoss()\noptimizer = T.optim.Adam(MLP_model.parameters(), lr = learn_rate, weight_decay = 0.005)     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model on the training data\nmin_valid_loss = np.inf\nfor epoch in range(epochs):\n    for inputs, labels in train_loader:\n        optimizer.zero_grad()\n        outputs = MLP_model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n    # Validate the model on the validation data\n    with T.no_grad():\n        val_loss = 0\n        for inputs, labels in validation_loader:\n            outputs = MLP_model(inputs)\n            val_loss += criterion(outputs, labels)\n        val_loss /= len(validation_loader)\n        \n\n    # Print the loss on the training and validation data\n    print(f\"Epoch {epoch+1}: Train loss: {loss.item():.4f} Validation loss: {val_loss.item():.4f}\")\n    \n    if min_valid_loss > val_loss:\n        print(f\"Epoch: {epoch+1} Validation Loss decreased: {min_valid_loss:.4f} -> {val_loss:.4f} Saving Model\")\n        min_valid_loss = val_loss\n        T.save(MLP_model.state_dict(), \"mlp_model.pt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Check F1\nimport sklearn.metrics\n\n#Load Best Model from Validation Loss\nMLP_model = MLPNet(14)\nMLP_model.load_state_dict(T.load(\"mlp_model.pt\"))\n\nwith T.no_grad():\n    dev_y = []\n    predicted_y = []\n    for inputs, labels in validation_loader:\n   \n        outputs = MLP_model(inputs)\n        output_probs = T.sigmoid(outputs)\n        predicted = T.round(outputs)\n\n        dev_y.extend(labels.tolist())\n        predicted_y.extend(predicted.tolist())\n\nf1 = sklearn.metrics.f1_score(dev_y, predicted_y)\naccuracy = sklearn.metrics.accuracy_score(dev_y, predicted_y)\n\nprint(f\"F1 score: {f1:.4f} Accuracy score: {accuracy:.4f}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing\nMLP_model = MLPNet(14)\nMLP_model.load_state_dict(T.load(\"mlp_model.pt\"))\nMLP_model.eval()\n\ny_toFile = []\n\nwith T.no_grad():\n    for inputs in test_loader:\n        outputs = MLP_model(inputs)\n        output_probs = T.sigmoid(outputs)\n        predicted_y = T.round(outputs)\n        \n        for values in predicted_y.numpy().flatten():\n            y_toFile.append(int(values))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = preprocessTest('/kaggle/input/mlfinalprojectdataset/test_without_label.txt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file = open('AnubhavKunduNN_test_result.txt', 'w')\n\nfor i in range(len(df_test['instance id'])):\n    file.write(str(df_test['instance id'].values[i]) + '\\t' + str(y_toFile[i]) + '\\n')\nfile.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}